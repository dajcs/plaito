{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fb0b50e-4d1d-4057-a9a9-c9d372cbc027",
   "metadata": {},
   "source": [
    "# Study Summaries Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47892fd5-0e3f-4ad4-b29c-360843656639",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc55b3d-c941-468f-8c51-d41e07f5075c",
   "metadata": {},
   "source": [
    "We are going to organize both summaries into predefined themes.  \n",
    "\n",
    "To analyze both summaries we define 4 themes for both summaries in such a way that the theme content is discussing roughly the same portion of the original study.\n",
    "\n",
    "The generic themes which are easily identifiable at both summaries are `Introduction`, `Methodology`, `Findings` and `Conclusion`.\n",
    "\n",
    "We are going to define a dictionary for both summaries a dictionary with the aforementioned keys and the values will be the actually title in the summary text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b95b0543-f60a-48bf-84c9-190d7bc79f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MySummary.txt themes\n",
    "my_themes = {\n",
    "    'Introduction': 'Introduction and Motivation',\n",
    "    'Methodology' : 'Research Methodology',\n",
    "    'Findings'    : 'Findings and Analysis',\n",
    "    'Conclusion'  : 'Limitations and Future Work'}\n",
    "\n",
    "# LLM_Summary.txt themes\n",
    "llm_themes = {\n",
    "    'Introduction': 'Introduction',\n",
    "    'Methodology' : 'Methodology',\n",
    "    'Findings'    : 'Key Findings',\n",
    "    'Conclusion'  : 'Conclusion and Future Work'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0bdef8-3e22-4f37-9a54-60f3cb3f6b9e",
   "metadata": {},
   "source": [
    "We are defining a function that is splitting the summaries text into sections based on the text headings.  \n",
    "The function is going to return a sections dictionary with the generic headings `Introduction`, `Methodology`, `Findings` and `Conclusion` as keys and the correponding text as values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "624dee7c-3ebb-4093-bb05-e5a1c4c795dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_sections(text, themes):\n",
    "    \"\"\"\n",
    "    Splits text into sections based on the provided theme headings.\n",
    "    Returns a dictionary with theme as key and corresponding text as value.\n",
    "    \"\"\"\n",
    "    sections = {}\n",
    "    # get a list of the actual text headings\n",
    "    text_headings = themes.values()\n",
    "    # create a reverse mapping of actual text_headings -> generic headings\n",
    "    generic_headings = {v:k for k,v in themes.items()}\n",
    "    # Create a regex pattern that matches any of the text headings.\n",
    "    # (Assuming that text headings appear at the beginning of a line)\n",
    "    pattern = r'(?m)^(' + '|'.join(re.escape(heading) for heading in text_headings) + r')'\n",
    "    \n",
    "    # Find all matches and split text accordingly.\n",
    "    splits = re.split(pattern, text)\n",
    "    # re.split returns a list where headings are also part of the result.\n",
    "    # The first element is any text before the first heading (if any).\n",
    "    current_heading = None\n",
    "    for segment in splits:\n",
    "        segment = segment.strip()\n",
    "        if segment in text_headings:\n",
    "            current_heading = segment\n",
    "            sections[generic_headings[current_heading]] = \"\"\n",
    "        elif current_heading:\n",
    "            sections[generic_headings[current_heading]] += segment + \"\\n\"\n",
    "    return sections\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b741c147-0509-40bb-b048-5aa6eafdff6e",
   "metadata": {},
   "source": [
    "Reading the summary files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "994369f7-ba24-4bcb-a0f8-1d01917c4068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the files\n",
    "with open(\"MySummary.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    my_summary_text = file.read()\n",
    "\n",
    "with open(\"LLM_Summary.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    llm_summary_text = file.read()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b462aa59-f5b9-4bd2-9a08-78edac1ab8ed",
   "metadata": {},
   "source": [
    "Extracting the sections for each summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5f0c7d6a-e131-4129-a021-57d1be7814d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract sections for each summary\n",
    "my_sections = extract_sections(my_summary_text, my_themes)\n",
    "llm_sections = extract_sections(llm_summary_text, llm_themes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9342769-4ee4-486f-bb4d-b01fdf0083fb",
   "metadata": {},
   "source": [
    "Checking and validation the section split result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "31adfe9e-7e47-4d3d-8b7c-351a194655c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_sections length: 4\n",
      "llm_sections length: 4\n"
     ]
    }
   ],
   "source": [
    "# check the number of sections\n",
    "print(\"my_sections length:\", len(my_sections))\n",
    "print(\"llm_sections length:\", len(llm_sections))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f300d140-19c7-4476-a2b9-7eec2adb4e0f",
   "metadata": {},
   "source": [
    "Visually inspecting the last section for both cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5d71b72a-9864-4fe9-a4e8-1b0e35f26686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Introduction', 'Methodology', 'Findings', 'Conclusion'])\n"
     ]
    }
   ],
   "source": [
    "print(my_sections.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d649b2b6-2b74-4096-8e41-8ee0775260dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "While domain models can clearly highlight missing requirements, this study did not evaluate whether analysts effectively identify and correct those omissions in practice. Future research should include user studies to explore the practical effectiveness of domain models in supporting requirements validation.\n",
      "\n",
      "Conclusion\n",
      "This empirical study provides concrete evidence supporting domain models' value as effective tools for completeness checking in natural-language requirements specifications. By systematically highlighting omissions, particularly entirely missing requirements, domain models can significantly improve requirements quality, making them valuable components of requirements engineering practice.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(my_sections['Conclusion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e2988d0e-9052-47d0-b2cc-04ebd1d9c7c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Introduction', 'Methodology', 'Findings', 'Conclusion'])\n"
     ]
    }
   ],
   "source": [
    "print(llm_sections.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f301d174-d866-405d-8e9f-e2b8636c221e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The study provides empirical evidence that domain models can help identify missing and under-specified requirements, though their effectiveness depends on how frequently concepts are referenced in the requirements. The results suggest that domain models should be complemented by other techniques for completeness checking. Future work should focus on user studies to evaluate whether analysts can effectively leverage domain models in practice.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(llm_sections['Conclusion'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717d357e-9b7e-432d-8a74-63363c08905d",
   "metadata": {},
   "source": [
    "## Diffing with Python's `difflib`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a57ef7-d23d-4b02-acb2-821ac506dea6",
   "metadata": {},
   "source": [
    "Using the built-in `difflib` module to compute and print the similarity ratio between two sections.  \n",
    "We are defining the function `similarity_ratios` which is going to compute the similarity between the sections of the two summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "877fa2df-3fbf-4f40-b16e-c65b5306727b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "def similarity_ratios(sequences1, sequences2):\n",
    "\n",
    "    ratios = {}\n",
    "    for theme in sequences1:\n",
    "        ratio = SequenceMatcher(\n",
    "            None,\n",
    "            sequences1[theme],\n",
    "            sequences2[theme]\n",
    "        ).ratio()\n",
    "        ratios[theme] = ratio\n",
    "    return ratios\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db323b7-4d52-44d0-a0a9-818a08a23c8b",
   "metadata": {},
   "source": [
    "Computing and displaying the similarity ratios between `my_sections` and `llm_sections`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "5102a322-e167-4c7a-b374-69b380cd9898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Introduction: 0.05\n",
      "Methodology : 0.13\n",
      "Findings    : 0.10\n",
      "Conclusion  : 0.05\n"
     ]
    }
   ],
   "source": [
    "my_seq_llm_seq_similarities = similarity_ratios(my_sections, llm_sections)\n",
    "for theme in my_seq_llm_seq_similarities:\n",
    "    print(f'{theme:12}: {my_seq_llm_seq_similarities[theme]:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b258417-3e8e-4ee2-aba4-cdaa306a9688",
   "metadata": {},
   "source": [
    "We can observe that the `Introduction` and `Conclusion` sections got only `5%` similarity, while the `Methodology` got `13%` and the `Findings` section got `10%` similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fed4aa-3adc-49f4-bccd-24669aef7d86",
   "metadata": {},
   "source": [
    "## TF-IDF and Cosine Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b58a27-77ba-4ca6-8382-712cd96660c0",
   "metadata": {},
   "source": [
    "Converting each section into a vector representation using TF-IDF (via scikit-learn), \n",
    "then calculating the cosine similarity.  \n",
    "This method highlights the overall textual differences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "765b6b96-d19c-4216-b41e-8e330939679d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.5850293584059283\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "texts = [my_sections['Methodology'], llm_sections['Methodology']]\n",
    "tfidf_matrix = vectorizer.fit_transform(texts)\n",
    "similarity = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])\n",
    "print(\"Cosine Similarity:\", similarity[0][0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "6237f1de-2ba4-4c0d-b8d4-6d04eed8f89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "texts = [my_sections['Methodology'], llm_sections['Methodology']]\n",
    "tfidf_matrix = vectorizer.fit_transform(texts)\n",
    "similarity = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])\n",
    "print(\"Cosine Similarity:\", similarity[0][0])\n",
    "\n",
    "\n",
    "def cosine_similarity(sections1, sections2):\n",
    "\n",
    "    cos_similarities = {}\n",
    "    \n",
    "    for theme in sections1:\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        print('theme =', theme)\n",
    "        texts = [sections1[theme], sections2[theme]]\n",
    "        tfidf_matrix = vectorizer.fit_transform(texts)\n",
    "        similarity = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])\n",
    "        print(type(similarity))\n",
    "        print(similarity)\n",
    "        cos_similarities[theme] = similarity[0][0]\n",
    "    return cos_similarities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "88bd80fc-8937-4974-9b8b-b924a7a2be6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theme = Introduction\n",
      "theme =   (0, 35)\t0.3088046674394297\n",
      "  (0, 85)\t0.20586977829295314\n",
      "  (0, 144)\t0.04822379836745153\n",
      "  (0, 134)\t0.37742792687041404\n",
      "  (0, 96)\t0.13724651886196876\n",
      "  (0, 45)\t0.04822379836745153\n",
      "  (0, 70)\t0.13724651886196876\n",
      "  (0, 18)\t0.04822379836745153\n",
      "  (0, 44)\t0.04822379836745153\n",
      "  (0, 117)\t0.04822379836745153\n",
      "  (0, 157)\t0.06862325943098438\n",
      "  (0, 48)\t0.04822379836745153\n",
      "  (0, 8)\t0.10293488914647657\n",
      "  (0, 82)\t0.04822379836745153\n",
      "  (0, 163)\t0.06862325943098438\n",
      "  (0, 118)\t0.09644759673490307\n",
      "  (0, 3)\t0.04822379836745153\n",
      "  (0, 68)\t0.2401814080084453\n",
      "  (0, 183)\t0.09644759673490307\n",
      "  (0, 126)\t0.03431162971549219\n",
      "  (0, 167)\t0.06862325943098438\n",
      "  (0, 61)\t0.09644759673490307\n",
      "  (0, 5)\t0.06862325943098438\n",
      "  (0, 130)\t0.04822379836745153\n",
      "  (0, 91)\t0.10293488914647657\n",
      "  :\t:\n",
      "  (0, 150)\t0.04822379836745153\n",
      "  (0, 149)\t0.04822379836745153\n",
      "  (0, 143)\t0.04822379836745153\n",
      "  (0, 72)\t0.04822379836745153\n",
      "  (0, 69)\t0.04822379836745153\n",
      "  (0, 2)\t0.04822379836745153\n",
      "  (0, 132)\t0.04822379836745153\n",
      "  (0, 169)\t0.04822379836745153\n",
      "  (0, 86)\t0.04822379836745153\n",
      "  (0, 33)\t0.04822379836745153\n",
      "  (0, 161)\t0.03431162971549219\n",
      "  (0, 16)\t0.04822379836745153\n",
      "  (0, 15)\t0.04822379836745153\n",
      "  (0, 75)\t0.04822379836745153\n",
      "  (0, 114)\t0.04822379836745153\n",
      "  (0, 168)\t0.04822379836745153\n",
      "  (0, 176)\t0.04822379836745153\n",
      "  (0, 62)\t0.04822379836745153\n",
      "  (0, 172)\t0.03431162971549219\n",
      "  (0, 148)\t0.03431162971549219\n",
      "  (0, 146)\t0.04822379836745153\n",
      "  (0, 49)\t0.04822379836745153\n",
      "  (0, 38)\t0.04822379836745153\n",
      "  (0, 40)\t0.04822379836745153\n",
      "  (0, 112)\t0.04822379836745153\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Indexing with sparse matrices is not supported except boolean indexing where matrix and index are equal shapes.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[143]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m my_seq_llm_seq_cosine_similarities = \u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmy_sections\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mllm_sections\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m theme \u001b[38;5;129;01min\u001b[39;00m my_seq_llm_seq_cosine_similarities:\n\u001b[32m      3\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtheme\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m12\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmy_seq_llm_seq_similarities[theme]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[141]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mcosine_similarity\u001b[39m\u001b[34m(sections1, sections2)\u001b[39m\n\u001b[32m     11\u001b[39m texts = [sections1[theme], sections2[theme]]\n\u001b[32m     12\u001b[39m tfidf_matrix = vectorizer.fit_transform(texts)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m similarity = \u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtfidf_matrix\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtfidf_matrix\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(similarity))\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(similarity)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[141]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mcosine_similarity\u001b[39m\u001b[34m(sections1, sections2)\u001b[39m\n\u001b[32m      9\u001b[39m vectorizer = TfidfVectorizer()\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mtheme =\u001b[39m\u001b[33m'\u001b[39m, theme)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m texts = [\u001b[43msections1\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtheme\u001b[49m\u001b[43m]\u001b[49m, sections2[theme]]\n\u001b[32m     12\u001b[39m tfidf_matrix = vectorizer.fit_transform(texts)\n\u001b[32m     13\u001b[39m similarity = cosine_similarity(tfidf_matrix[\u001b[32m0\u001b[39m:\u001b[32m1\u001b[39m], tfidf_matrix[\u001b[32m1\u001b[39m:\u001b[32m2\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\plaito\\Lib\\site-packages\\scipy\\sparse\\_index.py:52\u001b[39m, in \u001b[36mIndexMixin.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m     row, col = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     54\u001b[39m     \u001b[38;5;66;03m# Dispatch to specialized methods.\u001b[39;00m\n\u001b[32m     55\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(row, INT_TYPES):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\plaito\\Lib\\site-packages\\scipy\\sparse\\_index.py:162\u001b[39m, in \u001b[36mIndexMixin._validate_indices\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    160\u001b[39m     row, col = key.nonzero()\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     row, col = \u001b[43m_unpack_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    163\u001b[39m M, N = \u001b[38;5;28mself\u001b[39m.shape\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_validate_bool_idx\u001b[39m(\n\u001b[32m    166\u001b[39m     idx: npt.NDArray[np.bool_],\n\u001b[32m    167\u001b[39m     axis_size: \u001b[38;5;28mint\u001b[39m,\n\u001b[32m    168\u001b[39m     axis_name: \u001b[38;5;28mstr\u001b[39m\n\u001b[32m    169\u001b[39m ) -> npt.NDArray[np.int_]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\plaito\\Lib\\site-packages\\scipy\\sparse\\_index.py:327\u001b[39m, in \u001b[36m_unpack_index\u001b[39m\u001b[34m(index)\u001b[39m\n\u001b[32m    323\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_base\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m issparse\n\u001b[32m    324\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m issparse(row) \u001b[38;5;129;01mor\u001b[39;00m issparse(col):\n\u001b[32m    325\u001b[39m     \u001b[38;5;66;03m# Supporting sparse boolean indexing with both row and col does\u001b[39;00m\n\u001b[32m    326\u001b[39m     \u001b[38;5;66;03m# not work because spmatrix.ndim is always 2.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\n\u001b[32m    328\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mIndexing with sparse matrices is not supported \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    329\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mexcept boolean indexing where matrix and index \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    330\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mare equal shapes.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    331\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m row, col\n",
      "\u001b[31mIndexError\u001b[39m: Indexing with sparse matrices is not supported except boolean indexing where matrix and index are equal shapes."
     ]
    }
   ],
   "source": [
    "my_seq_llm_seq_cosine_similarities = cosine_similarity(my_sections, llm_sections)\n",
    "for theme in my_seq_llm_seq_cosine_similarities:\n",
    "    print(f'{theme:12}: {my_seq_llm_seq_similarities[theme]:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202651c9-987f-46f8-8e67-16302b5d4a39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
