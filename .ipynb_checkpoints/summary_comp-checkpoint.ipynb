{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fb0b50e-4d1d-4057-a9a9-c9d372cbc027",
   "metadata": {},
   "source": [
    "# Study Summaries Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47892fd5-0e3f-4ad4-b29c-360843656639",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc55b3d-c941-468f-8c51-d41e07f5075c",
   "metadata": {},
   "source": [
    "We are going to organize both summaries into predefined themes.  \n",
    "\n",
    "To analyze both summaries we define 4 themes for both summaries in such a way that the theme content is discussing roughly the same portion of the original study.\n",
    "\n",
    "The generic themes which are easily identifiable at both summaries are `Introduction`, `Methodology`, `Findings` and `Conclusion`.\n",
    "\n",
    "We are going to define a dictionary for both summaries a dictionary with the aforementioned keys and the values will be the actually title in the summary text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b95b0543-f60a-48bf-84c9-190d7bc79f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MySummary.txt themes\n",
    "my_themes = {\n",
    "    'Introduction': 'Introduction and Motivation',\n",
    "    'Methodology' : 'Research Methodology',\n",
    "    'Findings'    : 'Findings and Analysis',\n",
    "    'Conclusion'  : 'Limitations and Future Work'}\n",
    "\n",
    "# LLM_Summary.txt themes\n",
    "llm_themes = {\n",
    "    'Introduction': 'Introduction',\n",
    "    'Methodology' : 'Methodology',\n",
    "    'Findings'    : 'Key Findings',\n",
    "    'Conclusion'  : 'Conclusion and Future Work'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0bdef8-3e22-4f37-9a54-60f3cb3f6b9e",
   "metadata": {},
   "source": [
    "We are defining a function that is splitting the summaries text into sections based on the text headings.  \n",
    "The function is going to return a sections dictionary with the generic headings `Introduction`, `Methodology`, `Findings` and `Conclusion` as keys and the correponding text as values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "624dee7c-3ebb-4093-bb05-e5a1c4c795dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_sections(text, themes):\n",
    "    \"\"\"\n",
    "    Splits text into sections based on the provided theme headings.\n",
    "    Returns a dictionary with theme as key and corresponding text as value.\n",
    "    \"\"\"\n",
    "    sections = {}\n",
    "    # get a list of the actual text headings\n",
    "    text_headings = themes.values()\n",
    "    # create a reverse mapping of actual text_headings -> generic headings\n",
    "    generic_headings = {v:k for k,v in themes.items()}\n",
    "    # Create a regex pattern that matches any of the text headings.\n",
    "    # (Assuming that headings appear at the beginning of a line)\n",
    "    pattern = r'(?m)^(' + '|'.join(re.escape(heading) for heading in text_headings) + r')'\n",
    "    \n",
    "    # Find all matches and split text accordingly.\n",
    "    splits = re.split(pattern, text)\n",
    "    # re.split returns a list where headings are also part of the result.\n",
    "    # The first element is any text before the first heading (if any).\n",
    "    current_heading = None\n",
    "    for segment in splits:\n",
    "        segment = segment.strip()\n",
    "        if segment in text_headings:\n",
    "            current_heading = segment\n",
    "            sections[generic_headings[current_heading]] = \"\"\n",
    "        elif current_heading:\n",
    "            sections[generic_headings[current_heading]] += segment + \"\\n\"\n",
    "    return sections\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b741c147-0509-40bb-b048-5aa6eafdff6e",
   "metadata": {},
   "source": [
    "Reading the summary files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "994369f7-ba24-4bcb-a0f8-1d01917c4068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the files\n",
    "with open(\"MySummary.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    my_summary_text = file.read()\n",
    "\n",
    "with open(\"LLM_Summary.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    llm_summary_text = file.read()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b462aa59-f5b9-4bd2-9a08-78edac1ab8ed",
   "metadata": {},
   "source": [
    "Extracting the sections for each summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5f0c7d6a-e131-4129-a021-57d1be7814d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract sections for each summary\n",
    "my_sections = extract_sections(my_summary_text, my_themes)\n",
    "llm_sections = extract_sections(llm_summary_text, llm_themes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9342769-4ee4-486f-bb4d-b01fdf0083fb",
   "metadata": {},
   "source": [
    "Checking and validation the section split result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "31adfe9e-7e47-4d3d-8b7c-351a194655c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_sections length: 4\n",
      "llm_sections length: 4\n"
     ]
    }
   ],
   "source": [
    "# check the number of sections\n",
    "print(\"my_sections length:\", len(my_sections))\n",
    "print(\"llm_sections length:\", len(llm_sections))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f300d140-19c7-4476-a2b9-7eec2adb4e0f",
   "metadata": {},
   "source": [
    "Visually inspecting the last section for both cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5d71b72a-9864-4fe9-a4e8-1b0e35f26686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Introduction', 'Methodology', 'Findings', 'Conclusion'])\n"
     ]
    }
   ],
   "source": [
    "print(my_sections.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d649b2b6-2b74-4096-8e41-8ee0775260dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "While domain models can clearly highlight missing requirements, this study did not evaluate whether analysts effectively identify and correct those omissions in practice. Future research should include user studies to explore the practical effectiveness of domain models in supporting requirements validation.\n",
      "\n",
      "Conclusion\n",
      "This empirical study provides concrete evidence supporting domain models' value as effective tools for completeness checking in natural-language requirements specifications. By systematically highlighting omissions, particularly entirely missing requirements, domain models can significantly improve requirements quality, making them valuable components of requirements engineering practice.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(my_sections['Conclusion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e2988d0e-9052-47d0-b2cc-04ebd1d9c7c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Introduction', 'Methodology', 'Findings', 'Conclusion'])\n"
     ]
    }
   ],
   "source": [
    "print(llm_sections.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f301d174-d866-405d-8e9f-e2b8636c221e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The study provides empirical evidence that domain models can help identify missing and under-specified requirements, though their effectiveness depends on how frequently concepts are referenced in the requirements. The results suggest that domain models should be complemented by other techniques for completeness checking. Future work should focus on user studies to evaluate whether analysts can effectively leverage domain models in practice.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(llm_sections['Conclusion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dd6749-48f2-4e9b-9eb6-aa19f555836d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
