{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fb0b50e-4d1d-4057-a9a9-c9d372cbc027",
   "metadata": {},
   "source": [
    "# Study Summaries Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47892fd5-0e3f-4ad4-b29c-360843656639",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc55b3d-c941-468f-8c51-d41e07f5075c",
   "metadata": {},
   "source": [
    "We are going to organize both summaries into predefined themes.  \n",
    "\n",
    "By analyzing both summaries we define 4 themes for both summaries in such a way that the theme content is discussing roughly the same portion of the original study.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b95b0543-f60a-48bf-84c9-190d7bc79f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MySummary.txt themes\n",
    "my_themes = [\n",
    "    'Introduction and Motivation',\n",
    "    'Research Methodology',\n",
    "    'Findings and Analysis',\n",
    "    'Limitations and Future Work']\n",
    "\n",
    "# LLM_Summary.txt themes\n",
    "llm_themes = [\n",
    "    'Introduction',\n",
    "    'Methodology',\n",
    "    'Key Findings',\n",
    "    'Conclusion and Future Work']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0bdef8-3e22-4f37-9a54-60f3cb3f6b9e",
   "metadata": {},
   "source": [
    "We are defining a function that is splitting the summaries text into sections based on the theme headings:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "624dee7c-3ebb-4093-bb05-e5a1c4c795dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_sections(text, themes):\n",
    "    \"\"\"\n",
    "    Splits text into sections based on the provided theme headings.\n",
    "    Returns a dictionary with theme as key and corresponding text as value.\n",
    "    \"\"\"\n",
    "    sections = {}\n",
    "    # Create a regex pattern that matches any of the theme headings.\n",
    "    # (Assuming that headings appear at the beginning of a line)\n",
    "    pattern = r'(?m)^(' + '|'.join(re.escape(theme) for theme in themes) + r')'\n",
    "    \n",
    "    # Find all matches and split text accordingly.\n",
    "    splits = re.split(pattern, text)\n",
    "    # re.split returns a list where headings are also part of the result.\n",
    "    # The first element is any text before the first heading (if any).\n",
    "    current_heading = None\n",
    "    for segment in splits:\n",
    "        segment = segment.strip()\n",
    "        if segment in themes:\n",
    "            current_heading = segment\n",
    "            sections[current_heading] = \"\"\n",
    "        elif current_heading:\n",
    "            sections[current_heading] += segment + \"\\n\"\n",
    "    return sections\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b741c147-0509-40bb-b048-5aa6eafdff6e",
   "metadata": {},
   "source": [
    "Reading the summary files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "994369f7-ba24-4bcb-a0f8-1d01917c4068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the files\n",
    "with open(\"MySummary.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    my_summary_text = file.read()\n",
    "\n",
    "with open(\"LLM_Summary.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    llm_summary_text = file.read()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b462aa59-f5b9-4bd2-9a08-78edac1ab8ed",
   "metadata": {},
   "source": [
    "Extracting the sections for each summary. The sections will be stored in a dictionary with keys from `my_themes` and `llm_themes` and the values will be the text content of the section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5f0c7d6a-e131-4129-a021-57d1be7814d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract sections for each summary\n",
    "my_sections = extract_sections(my_summary_text, my_themes)\n",
    "llm_sections = extract_sections(llm_summary_text, llm_themes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9342769-4ee4-486f-bb4d-b01fdf0083fb",
   "metadata": {},
   "source": [
    "Checking and validation the section split result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "31adfe9e-7e47-4d3d-8b7c-351a194655c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_sections length: 4\n",
      "llm_sections length: 4\n"
     ]
    }
   ],
   "source": [
    "# check the number of sections\n",
    "print(\"my_sections length:\", len(my_sections))\n",
    "print(\"llm_sections length:\", len(llm_sections))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f300d140-19c7-4476-a2b9-7eec2adb4e0f",
   "metadata": {},
   "source": [
    "Visually inspecting the last section for both cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5d71b72a-9864-4fe9-a4e8-1b0e35f26686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Introduction and Motivation', 'Research Methodology', 'Findings and Analysis', 'Limitations and Future Work'])\n"
     ]
    }
   ],
   "source": [
    "print(my_sections.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d649b2b6-2b74-4096-8e41-8ee0775260dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "While domain models can clearly highlight missing requirements, this study did not evaluate whether analysts effectively identify and correct those omissions in practice. Future research should include user studies to explore the practical effectiveness of domain models in supporting requirements validation.\n",
      "\n",
      "Conclusion\n",
      "This empirical study provides concrete evidence supporting domain models' value as effective tools for completeness checking in natural-language requirements specifications. By systematically highlighting omissions, particularly entirely missing requirements, domain models can significantly improve requirements quality, making them valuable components of requirements engineering practice.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(my_sections['Limitations and Future Work'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e2988d0e-9052-47d0-b2cc-04ebd1d9c7c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Introduction', 'Methodology', 'Key Findings', 'Conclusion and Future Work'])\n"
     ]
    }
   ],
   "source": [
    "print(llm_sections.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f301d174-d866-405d-8e9f-e2b8636c221e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The study provides empirical evidence that domain models can help identify missing and under-specified requirements, though their effectiveness depends on how frequently concepts are referenced in the requirements. The results suggest that domain models should be complemented by other techniques for completeness checking. Future work should focus on user studies to evaluate whether analysts can effectively leverage domain models in practice.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(llm_sections['Conclusion and Future Work'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5835e86a-e5de-4581-a33a-7fc38dd28b82",
   "metadata": {},
   "source": [
    "In order to streamline the analysis we are going to replace the keys in both section dictionaries with simplified theme headings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "836174b3-f4b8-4078-ab34-5ff3363e3f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simplified theme headings\n",
    "themes = [\n",
    "    'Introduction',\n",
    "    'Methodology',\n",
    "    'Findings',\n",
    "    'Conclusion']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c918d287-e8a3-4129-b968-1a5cb4b29b09",
   "metadata": {},
   "source": [
    "Swapping keys for `my_sections`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "147086b5-1aae-4f40-9c89-db32f6401d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping from old keys to new keys\n",
    "mapping = dict(zip(my_themes, themes))\n",
    "\n",
    "# Use a dictionary comprehension to create a new dictionary with swapped keys\n",
    "# mapping.get(key, key) makes sure if a key is not in the mapping then there is no change\n",
    "my_sections = {mapping.get(key, key): value for key, value in my_sections.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "57a0e8c2-f330-423f-8f07-368f8f25d62f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "While domain models can clearly highlight missing requirements, this study did not evaluate whether analysts effectively identify and correct those omissions in practice. Future research should include user studies to explore the practical effectiveness of domain models in supporting requirements validation.\n",
      "\n",
      "Conclusion\n",
      "This empirical study provides concrete evidence supporting domain models' value as effective tools for completeness checking in natural-language requirements specifications. By systematically highlighting omissions, particularly entirely missing requirements, domain models can significantly improve requirements quality, making them valuable components of requirements engineering practice.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(my_sections['Conclusion'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbdb0b9-d715-414e-ad5c-ad71eae16b90",
   "metadata": {},
   "source": [
    "Swapping keys for `llm_sections`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1e78d6d3-6be3-48e3-bfdb-d3b1df5a604d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping from old keys to new keys\n",
    "mapping = dict(zip(llm_themes, themes))\n",
    "\n",
    "# Use a dictionary comprehension to create a new dictionary with swapped keys\n",
    "# mapping.get(key, key) makes sure if a key is not in the mapping then there is no change\n",
    "llm_sections = {mapping.get(key, key): value for key, value in llm_sections.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d3c112e5-c6d1-46a4-b3f6-139e9a719740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The study provides empirical evidence that domain models can help identify missing and under-specified requirements, though their effectiveness depends on how frequently concepts are referenced in the requirements. The results suggest that domain models should be complemented by other techniques for completeness checking. Future work should focus on user studies to evaluate whether analysts can effectively leverage domain models in practice.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(llm_sections['Conclusion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dd6749-48f2-4e9b-9eb6-aa19f555836d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
